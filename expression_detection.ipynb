{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial expression detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook captures emotional states based on facial expressions using real-time webcam capture. It is used to test the models trained in the 'expression_model.ipynb' notebook in a real environment with variance in camera placement, lighting, etc. \n",
    "\n",
    "##### Each model is tested for its predictions in the following order\n",
    "1. Neutral\n",
    "2. Happy\n",
    "3. Sad\n",
    "4. Angry\n",
    "5. Surprise\n",
    "6. Fear\n",
    "7. Disgust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import timeit\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.2.3\n",
      "numpy: 1.23.5\n",
      "opencv-python: 4.10.0\n",
      "dlib: 19.24.6\n",
      "tensorflow: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "# Libraries and versions\n",
    "libraries = {\n",
    "    'pandas': pd.__version__,\n",
    "    'numpy': np.__version__,\n",
    "    'opencv-python': cv2.__version__,\n",
    "    'dlib': dlib.__version__,\n",
    "    'tensorflow': tf.__version__,\n",
    "}\n",
    "\n",
    "# Write to the requirements file and print\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    for lib, version in libraries.items():\n",
    "        f.write(f\"{lib}=={version}\\n\")\n",
    "        print(f\"{lib}: {version}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves loaded model metadata to a pickle file.\n",
    "def pickle_metadata(model_path, emotions_map, pickle_path):\n",
    "    metadata = {\n",
    "        \"model_path\": model_path,\n",
    "        \"emotion_labels\": emotions_map\n",
    "    }\n",
    "    \n",
    "    with open(pickle_path, 'wb') as pkl_file:\n",
    "        pickle.dump(metadata, pkl_file)\n",
    "    \n",
    "    print(f\"Model metadata saved to: {pickle_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time emotion detection from webcam capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs real-time emotion detection with user feedback using pre-trained model and video capture.\n",
    "def emotion_detection(pickle_path, img_size, emotion_frames):\n",
    "    # Load Dlib's face detector\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # Load model and metadata from the pickle file\n",
    "    with open(pickle_path, 'rb') as pickle_file:\n",
    "        model_metadata = pickle.load(pickle_file)\n",
    "\n",
    "    # Initialize model and motions labels from pickle metadata\n",
    "    model = load_model(model_metadata[\"model_path\"])   # Load the pre-trained model \n",
    "    emotions = model_metadata[\"emotion_labels\"]  # Load the emotion classes\n",
    "    \n",
    "    # Initialize emotion count dictionary and variable for tracking total no. of emotions observed\n",
    "    # Used to return a summary of all observed emotions without relying on emotion stabilization \n",
    "    emotion_count = {label: 0 for label in emotions} # Emotion label dictionary \n",
    "    emotion_count_total = 0 \n",
    "    \n",
    "    # Initialize user key-press feedback (i.e. True or False emotion observed)\n",
    "    user_feedback = []             # List for emotion feedback\n",
    "    detected_emotion = None        # Track the last emotion that was logged\n",
    "\n",
    "    # Initialize variable for stabilizing emotions predicted by the model\n",
    "    # Used to ensure that predicted emotions are stable for a certain ammount of frames (i.e. 'emotion_frames' input argument)\n",
    "    # Helps to provide the users with enough time to identify and provide feedback for the observed emotion\n",
    "    emotion_queue = []   # FIFO queue for tracking observed emotions in the input frame count threshold, used as a buffer to stabilize emotion over time\n",
    "    emotion_prev = None  # Previous stabilized emotion from queue\n",
    "    emotion_curr = None  # Current stabilized emotion from queue\n",
    "    stable_frames = 0    # Counter for how many frames the emotion has been stable\n",
    "\n",
    "    # Initialize video capture from webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Initial color for rectangle around detected face: Used to revert color change of user input key-press \n",
    "    # True: Green, False: Red, No input: Green\n",
    "    rect_color = (255, 0, 0) # Green color\n",
    "\n",
    "    # Guide text for first 10 seconds\n",
    "    start_time = timeit.default_timer() # Start timer: Used to clear the text\n",
    "    text, font, scale, thickness = \"Press 'T' if the detected emotion is correct and 'F' if incorrect\", cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1\n",
    "    text_size = cv2.getTextSize(text, font, scale, thickness)[0]\n",
    "    text_pos = ((int(cap.get(cv2.CAP_PROP_FRAME_WIDTH )) - text_size[0]) // 2, int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT )) - 20) # Display in the middle at bottom\n",
    "\n",
    "    # Terminal start-up prints\n",
    "    print(\"Press 'T' if the detected emotion is correct and 'F' if incorrect\")\n",
    "    print(\"Press 'Q' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Print user input instructions \n",
    "        if start_time is not None:\n",
    "            # Get elapsed time since starting video capture\n",
    "            elapsed_time = timeit.default_timer() - start_time\n",
    "            # Print 10 seconds\n",
    "            if elapsed_time  < 10:\n",
    "                cv2.putText(frame, text, text_pos, font, scale, (180, 190, 180), thickness)\n",
    "            else:\n",
    "                # Clear start_time variable afterwards \n",
    "                start_time = None\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces using Dlib's face detector (performs better than the Haar Cascade Classifier previously used)\n",
    "        faces = detector(gray_frame)\n",
    "\n",
    "        # For each detected face (i.e. coordinates of detected face)\n",
    "        for face in faces:\n",
    "            # Capture face region and repare image for model classification\n",
    "            x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "            face_region = gray_frame[y:y+h, x:x+w]                   # Capture face region\n",
    "            face_resized = cv2.resize(face_region, img_size)         # Resize region to input image size\n",
    "            face_normalized = face_resized / 255.0                   # Normalize\n",
    "            face_reshaped = np.expand_dims(face_normalized, axis=-1) # Add channel dimension\n",
    "            face_input = np.expand_dims(face_reshaped, axis=0)       # Add batch dimension\n",
    "\n",
    "            # Predict the emotion using the pre-trained model\n",
    "            prediction = model.predict(face_input, verbose=0)        # Pre-trained model loaded from the pickle file\n",
    "            prediction_max = np.argmax(prediction)                   # Index of emotion with the highest probability\n",
    "            prediction_label = emotions[prediction_max]              # Map emotion with the highest probability to the labels of the pickle file \n",
    "\n",
    "            # Populate the emotion queue to obtained the max obs. emotion of the desired frames (i.e. the frame input argument)\n",
    "            # Stabilizes emotion prediction to enable user feedback\n",
    "            emotion_queue.append(prediction_label)   # Appends predicted emotions\n",
    "            if len(emotion_queue) > emotion_frames:   \n",
    "                emotion_queue.pop(0)                 # Pop first emotion label if queue exceeds input frames\n",
    "                \n",
    "            # Get the current emotion from the emotion prediction queue\n",
    "            emotion_curr = max(set(emotion_queue), key=emotion_queue.count)  # Max observed emotion label is the current (stable) emotion\n",
    "    \n",
    "            # Track changes in observed emotion\n",
    "            if emotion_curr == emotion_prev:\n",
    "                # Increase stable frames value if the emotion labels remains the same\n",
    "                stable_frames += 1          # Increment frames\n",
    "            else:\n",
    "                # Reset stable frames value and previous label when a new emotion is observed. \n",
    "                emotion_prev = emotion_curr # Update previous observed emotion label\n",
    "                stable_frames = 1           # Reset frames\n",
    "  \n",
    "            # Detect stabilized emotions (i.e. when an emotion has been observed for longer than the emotion frame input threshold argument)\n",
    "            if stable_frames >= emotion_frames:\n",
    "                if emotion_curr != detected_emotion:\n",
    "                    detected_emotion = emotion_curr  # Define or update the detected emotion\n",
    "\n",
    "            # Display the predicted emotion top left corner\n",
    "            if detected_emotion:\n",
    "                cv2.putText(frame, detected_emotion, (265, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 255, 100), 2)\n",
    "                \n",
    "            # Display rectangle around the face region with current color\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), rect_color, 2)\n",
    "            \n",
    "            # Reset rectangle color to blue\n",
    "            if stable_frames > 5:\n",
    "                rect_color = (255, 0, 0)\n",
    "\n",
    "            # Update emotion label and total counters\n",
    "            emotion_count[prediction_label] += 1  # Emotion label individual counts\n",
    "            emotion_count_total += 1              # Emotion label individual counts\n",
    "\n",
    "        # Display detection text\n",
    "        cv2.putText(frame, \"Detect emotion:\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 255, 100), 2)\n",
    "\n",
    "        # Display image with expression classification annotation\n",
    "        cv2.imshow('Facial Expression Detection', frame)\n",
    "\n",
    "        # Handle key presses\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # Press 'T' to mark the the current stable emotion as false\n",
    "        if key == ord('t'):  \n",
    "            if len(faces) > 0:\n",
    "                rect_color = (0, 255, 0)                         # Update rectangle color to green shortly\n",
    "                print(f\"Set emotion '{emotion_curr}' as true.\")  # Print choice in terminal\n",
    "                # Append to user feedback list\n",
    "                user_feedback.append({\n",
    "                    \"timestamp\": datetime.datetime.now(),\n",
    "                    \"emotion\": emotion_curr,\n",
    "                    \"true\": True\n",
    "                })\n",
    "        # Press 'F' to mark the the current stable emotion as false\n",
    "        elif key == ord('f'): \n",
    "            if len(faces) > 0:\n",
    "                rect_color = (0, 0, 255)                          # Update rectangle color to red shortly\n",
    "                print(f\"Set emotion '{emotion_curr}' as false.\")  # Print choice in terminal\n",
    "                # Append to user feedback list\n",
    "                user_feedback.append({\n",
    "                    \"timestamp\": datetime.datetime.now(),\n",
    "                    \"emotion\": emotion_curr,\n",
    "                    \"true\": False\n",
    "                })\n",
    "        # Press 'Q' to exit the loop       \n",
    "        elif key == ord('q'):  \n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Calculate percentages and determine the overall state\n",
    "    if emotion_count_total > 0:\n",
    "        print(\"\\nEmotion Summary:\")\n",
    "        overall_state = max(emotion_count, key=emotion_count.get)  # Get most frequently detected emotion\n",
    "        # Print percentage for each emotional state\n",
    "        for emotion, count in emotion_count.items():\n",
    "            percentage = (count / emotion_count_total) * 100\n",
    "            print(f\"{emotion}: {percentage:.2f}% \")\n",
    "        # Print the most frequently detected emotion\n",
    "        print(f\"\\nOverall State: {overall_state} \")\n",
    "    else:\n",
    "        print(\"\\nNo emotions were detected.\")\n",
    "\n",
    "    # Save user feedback data as a DataFrame\n",
    "    user_feedback_df = pd.DataFrame(user_feedback)\n",
    "\n",
    "    # Calculate and print overall true score from the df\n",
    "    if not user_feedback_df.empty:\n",
    "        true_score = user_feedback_df[\"true\"].mean() * 100\n",
    "        print(f\"\\nOverall True Score: {true_score:.2f}%\")\n",
    "    else:\n",
    "        print(\"\\nNo feedback recorded.\")\n",
    "\n",
    "    # Return user feedback dataframe\n",
    "    return user_feedback_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion detection using model pre-trained on the FER-2013 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metadata saved to: expression_model_FER_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "emotions_map_fer = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "pickle_metadata(\"expression_model_FER.h5\", emotions_map_fer, \"expression_model_FER_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'T' if the detected emotion is correct and 'F' if incorrect\n",
      "Press 'Q' to quit.\n",
      "Set emotion 'Fear' as false.\n",
      "Set emotion 'Neutral' as true.\n",
      "Set emotion 'Happy' as true.\n",
      "Set emotion 'Sad' as true.\n",
      "Set emotion 'Angry' as true.\n",
      "Set emotion 'Fear' as false.\n",
      "Set emotion 'Fear' as true.\n",
      "Set emotion 'Sad' as false.\n",
      "\n",
      "Emotion Summary:\n",
      "Angry: 6.33% \n",
      "Disgust: 0.00% \n",
      "Fear: 19.49% \n",
      "Happy: 6.43% \n",
      "Sad: 42.93% \n",
      "Surprise: 0.00% \n",
      "Neutral: 24.83% \n",
      "\n",
      "Overall State: Sad \n",
      "\n",
      "Overall True Score: 62.50%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>emotion</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-22 12:04:02.901527</td>\n",
       "      <td>Fear</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-22 12:04:06.290528</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-22 12:04:18.140090</td>\n",
       "      <td>Happy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-22 12:04:22.896089</td>\n",
       "      <td>Sad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-22 12:04:36.528089</td>\n",
       "      <td>Angry</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-22 12:04:43.004089</td>\n",
       "      <td>Fear</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-22 12:05:52.823273</td>\n",
       "      <td>Fear</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-22 12:06:35.654849</td>\n",
       "      <td>Sad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  emotion   true\n",
       "0 2024-11-22 12:04:02.901527     Fear  False\n",
       "1 2024-11-22 12:04:06.290528  Neutral   True\n",
       "2 2024-11-22 12:04:18.140090    Happy   True\n",
       "3 2024-11-22 12:04:22.896089      Sad   True\n",
       "4 2024-11-22 12:04:36.528089    Angry   True\n",
       "5 2024-11-22 12:04:43.004089     Fear  False\n",
       "6 2024-11-22 12:05:52.823273     Fear   True\n",
       "7 2024-11-22 12:06:35.654849      Sad  False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start webcam capture and emotion detection for FER-2013 model\n",
    "emotion_detection(\"expression_model_FER_metadata.pkl\", (48, 48), 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the evaluation of the model, we expect it to have problems predicting most emotional states, except for 'happy' and 'surprise'. \n",
    "\n",
    "The models fail to correctly predict 'surprise' and 'disgust', and it was difficult to capture the correct emotional states. There also seems to be a strong bias towards the emotional state 'sad'.\n",
    "\n",
    "Overall, it performed poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion detection using model pre-trained on the RAF-DB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metadata saved to: expression_model_RAF_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "emotions_map_raf = ['Surprise', 'Fear', 'Disgust', 'Happiness', 'Sadness', 'Anger', 'Neutral']\n",
    "pickle_metadata(\"expression_model_RAF.h5\", emotions_map_raf, \"expression_model_RAF_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'T' if the detected emotion is correct and 'F' if incorrect\n",
      "Press 'Q' to quit.\n",
      "Set emotion 'Neutral' as true.\n",
      "Set emotion 'Happiness' as true.\n",
      "Set emotion 'Sadness' as true.\n",
      "Set emotion 'Anger' as true.\n",
      "Set emotion 'Surprise' as true.\n",
      "Set emotion 'Fear' as false.\n",
      "Set emotion 'Fear' as true.\n",
      "Set emotion 'Disgust' as true.\n",
      "\n",
      "Emotion Summary:\n",
      "Surprise: 21.73% \n",
      "Fear: 2.69% \n",
      "Disgust: 8.64% \n",
      "Happiness: 7.06% \n",
      "Sadness: 32.87% \n",
      "Anger: 17.64% \n",
      "Neutral: 9.38% \n",
      "\n",
      "Overall State: Sadness \n",
      "\n",
      "Overall True Score: 87.50%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>emotion</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-22 12:25:11.955855</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-22 12:25:16.009923</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-22 12:25:20.006924</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-22 12:25:27.385924</td>\n",
       "      <td>Anger</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-22 12:25:31.782925</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-22 12:25:44.267923</td>\n",
       "      <td>Fear</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-22 12:25:45.820925</td>\n",
       "      <td>Fear</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-22 12:26:55.292496</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp    emotion   true\n",
       "0 2024-11-22 12:25:11.955855    Neutral   True\n",
       "1 2024-11-22 12:25:16.009923  Happiness   True\n",
       "2 2024-11-22 12:25:20.006924    Sadness   True\n",
       "3 2024-11-22 12:25:27.385924      Anger   True\n",
       "4 2024-11-22 12:25:31.782925   Surprise   True\n",
       "5 2024-11-22 12:25:44.267923       Fear  False\n",
       "6 2024-11-22 12:25:45.820925       Fear   True\n",
       "7 2024-11-22 12:26:55.292496    Disgust   True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start webcam capture and emotion detection for RAF-DB model\n",
    "emotion_detection(\"expression_model_RAF_metadata.pkl\", (100, 100), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the evaluation of the model, we expect it to have problems predicting only the emotional state 'fear'.\n",
    "\n",
    "The models correctly predicted all emotional states. However, correctly predicting the emotional state 'fear' took a little longer than the rest, mostly overlapping with 'sad', although no other bias was observed during experiment. \n",
    "\n",
    "Overall it performed really well and it was easy to get it to make the correct predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion detection using model pre-trained on FER-2013 and RAF-DB combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metadata saved to: expression_model_COMB_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "emotions_map_comb = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "pickle_metadata(\"expression_model_COMB.h5\", emotions_map_comb, \"expression_model_COMB_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'T' if the detected emotion is correct and 'F' if incorrect\n",
      "Press 'Q' to quit.\n",
      "Set emotion 'Sad' as false.\n",
      "Set emotion 'Happy' as true.\n",
      "Set emotion 'Sad' as true.\n",
      "Set emotion 'Angry' as true.\n",
      "Set emotion 'Surprise' as true.\n",
      "Set emotion 'Surprise' as true.\n",
      "Set emotion 'Sad' as false.\n",
      "\n",
      "Emotion Summary:\n",
      "Angry: 12.76% \n",
      "Disgust: 0.00% \n",
      "Fear: 7.09% \n",
      "Happy: 10.70% \n",
      "Sad: 48.84% \n",
      "Surprise: 19.20% \n",
      "Neutral: 1.42% \n",
      "\n",
      "Overall State: Sad \n",
      "\n",
      "Overall True Score: 71.43%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>emotion</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-22 12:38:38.198864</td>\n",
       "      <td>Sad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-22 12:38:42.788864</td>\n",
       "      <td>Happy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-22 12:38:48.124863</td>\n",
       "      <td>Sad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-22 12:38:53.257864</td>\n",
       "      <td>Angry</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-22 12:39:02.670865</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-22 12:39:48.431016</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-22 12:40:04.249034</td>\n",
       "      <td>Sad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp   emotion   true\n",
       "0 2024-11-22 12:38:38.198864       Sad  False\n",
       "1 2024-11-22 12:38:42.788864     Happy   True\n",
       "2 2024-11-22 12:38:48.124863       Sad   True\n",
       "3 2024-11-22 12:38:53.257864     Angry   True\n",
       "4 2024-11-22 12:39:02.670865  Surprise   True\n",
       "5 2024-11-22 12:39:48.431016  Surprise   True\n",
       "6 2024-11-22 12:40:04.249034       Sad  False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start webcam capture and emotion detection for RAF-DB model\n",
    "emotion_detection(\"expression_model_COMB_metadata.pkl\", (100, 100), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the evaluation of the model, we expect it to have problems predicting 'fear' and 'disgust'. \n",
    "\n",
    "The model is not able to predict 'neutral' and 'disgust', but the other emotional states were fairly easy to capture. It retains much of the bias towards 'sad' from the model trained using only the FER-2013 dataset. \n",
    "\n",
    "Overall, it performed reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of real-time facial expression prediction, both models trained on the FER-2013 dataset performed below the required standard in this real-life situation. However, the model trained on the RAF-DB dataset performed really well and proved to be very accurate under the test conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 Kernel",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
